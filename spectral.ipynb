{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3fc5663213ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClusterMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_float_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'base'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Algorithms for spectral clustering\"\"\"\n",
    "\n",
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "#         Brian Cheung\n",
    "#         Wei LI <kuantkid@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ..base import BaseEstimator, ClusterMixin\n",
    "from ..utils import check_random_state, as_float_array\n",
    "from ..utils.validation import _deprecate_positional_args\n",
    "from ..utils.deprecation import deprecated\n",
    "from ..metrics.pairwise import pairwise_kernels\n",
    "from ..neighbors import kneighbors_graph, NearestNeighbors\n",
    "from ..manifold import spectral_embedding\n",
    "from ._kmeans import k_means\n",
    "\n",
    "\n",
    "@_deprecate_positional_args\n",
    "def discretize(vectors, *, copy=True, max_svd_restarts=30, n_iter_max=20,\n",
    "               random_state=None):\n",
    "    \"\"\"Search for a partition matrix (clustering) which is closest to the\n",
    "    eigenvector embedding.\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors : array-like of shape (n_samples, n_clusters)\n",
    "        The embedding space of the samples.\n",
    "    copy : bool, default=True\n",
    "        Whether to copy vectors, or perform in-place normalization.\n",
    "    max_svd_restarts : int, default=30\n",
    "        Maximum number of attempts to restart SVD if convergence fails\n",
    "    n_iter_max : int, default=30\n",
    "        Maximum number of iterations to attempt in rotation and partition\n",
    "        matrix search if machine precision convergence is not reached\n",
    "    random_state : int, RandomState instance, default=None\n",
    "        Determines random number generation for rotation matrix initialization.\n",
    "        Use an int to make the randomness deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    Returns\n",
    "    -------\n",
    "    labels : array of integers, shape: n_samples\n",
    "        The labels of the clusters.\n",
    "    References\n",
    "    ----------\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    Notes\n",
    "    -----\n",
    "    The eigenvector embedding is used to iteratively search for the\n",
    "    closest discrete partition.  First, the eigenvector embedding is\n",
    "    normalized to the space of partition matrices. An optimal discrete\n",
    "    partition matrix closest to this normalized embedding multiplied by\n",
    "    an initial rotation is calculated.  Fixing this discrete partition\n",
    "    matrix, an optimal rotation matrix is calculated.  These two\n",
    "    calculations are performed until convergence.  The discrete partition\n",
    "    matrix is returned as the clustering solution.  Used in spectral\n",
    "    clustering, this method tends to be faster and more robust to random\n",
    "    initialization than k-means.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.sparse import csc_matrix\n",
    "    from scipy.linalg import LinAlgError\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    vectors = as_float_array(vectors, copy=copy)\n",
    "\n",
    "    eps = np.finfo(float).eps\n",
    "    n_samples, n_components = vectors.shape\n",
    "\n",
    "    # Normalize the eigenvectors to an equal length of a vector of ones.\n",
    "    # Reorient the eigenvectors to point in the negative direction with respect\n",
    "    # to the first element.  This may have to do with constraining the\n",
    "    # eigenvectors to lie in a specific quadrant to make the discretization\n",
    "    # search easier.\n",
    "    norm_ones = np.sqrt(n_samples)\n",
    "    for i in range(vectors.shape[1]):\n",
    "        vectors[:, i] = (vectors[:, i] / np.linalg.norm(vectors[:, i])) \\\n",
    "            * norm_ones\n",
    "        if vectors[0, i] != 0:\n",
    "            vectors[:, i] = -1 * vectors[:, i] * np.sign(vectors[0, i])\n",
    "\n",
    "    # Normalize the rows of the eigenvectors.  Samples should lie on the unit\n",
    "    # hypersphere centered at the origin.  This transforms the samples in the\n",
    "    # embedding space to the space of partition matrices.\n",
    "    vectors = vectors / np.sqrt((vectors ** 2).sum(axis=1))[:, np.newaxis]\n",
    "\n",
    "    svd_restarts = 0\n",
    "    has_converged = False\n",
    "\n",
    "    # If there is an exception we try to randomize and rerun SVD again\n",
    "    # do this max_svd_restarts times.\n",
    "    while (svd_restarts < max_svd_restarts) and not has_converged:\n",
    "\n",
    "        # Initialize first column of rotation matrix with a row of the\n",
    "        # eigenvectors\n",
    "        rotation = np.zeros((n_components, n_components))\n",
    "        rotation[:, 0] = vectors[random_state.randint(n_samples), :].T\n",
    "\n",
    "        # To initialize the rest of the rotation matrix, find the rows\n",
    "        # of the eigenvectors that are as orthogonal to each other as\n",
    "        # possible\n",
    "        c = np.zeros(n_samples)\n",
    "        for j in range(1, n_components):\n",
    "            # Accumulate c to ensure row is as orthogonal as possible to\n",
    "            # previous picks as well as current one\n",
    "            c += np.abs(np.dot(vectors, rotation[:, j - 1]))\n",
    "            rotation[:, j] = vectors[c.argmin(), :].T\n",
    "\n",
    "        last_objective_value = 0.0\n",
    "        n_iter = 0\n",
    "\n",
    "        while not has_converged:\n",
    "            n_iter += 1\n",
    "\n",
    "            t_discrete = np.dot(vectors, rotation)\n",
    "\n",
    "            labels = t_discrete.argmax(axis=1)\n",
    "            vectors_discrete = csc_matrix(\n",
    "                (np.ones(len(labels)), (np.arange(0, n_samples), labels)),\n",
    "                shape=(n_samples, n_components))\n",
    "\n",
    "            t_svd = vectors_discrete.T * vectors\n",
    "\n",
    "            try:\n",
    "                U, S, Vh = np.linalg.svd(t_svd)\n",
    "                svd_restarts += 1\n",
    "            except LinAlgError:\n",
    "                print(\"SVD did not converge, randomizing and trying again\")\n",
    "                break\n",
    "\n",
    "            ncut_value = 2.0 * (n_samples - S.sum())\n",
    "            if ((abs(ncut_value - last_objective_value) < eps) or\n",
    "                    (n_iter > n_iter_max)):\n",
    "                has_converged = True\n",
    "            else:\n",
    "                # otherwise calculate rotation and continue\n",
    "                last_objective_value = ncut_value\n",
    "                rotation = np.dot(Vh.T, U.T)\n",
    "\n",
    "    if not has_converged:\n",
    "        raise LinAlgError('SVD did not converge')\n",
    "    return labels\n",
    "\n",
    "\n",
    "@_deprecate_positional_args\n",
    "def spectral_clustering(affinity, *, n_clusters=8, n_components=None,\n",
    "                        eigen_solver=None, random_state=None, n_init=10,\n",
    "                        eigen_tol=0.0, assign_labels='kmeans',\n",
    "                        verbose=False):\n",
    "    \"\"\"Apply clustering to a projection of the normalized Laplacian.\n",
    "    In practice Spectral Clustering is very useful when the structure of\n",
    "    the individual clusters is highly non-convex or more generally when\n",
    "    a measure of the center and spread of the cluster is not a suitable\n",
    "    description of the complete cluster. For instance, when clusters are\n",
    "    nested circles on the 2D plane.\n",
    "    If affinity is the adjacency matrix of a graph, this method can be\n",
    "    used to find normalized graph cuts.\n",
    "    Read more in the :ref:`User Guide <spectral_clustering>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    affinity : {array-like, sparse matrix} of shape (n_samples, n_samples)\n",
    "        The affinity matrix describing the relationship of the samples to\n",
    "        embed. **Must be symmetric**.\n",
    "        Possible examples:\n",
    "          - adjacency matrix of a graph,\n",
    "          - heat kernel of the pairwise distance matrix of the samples,\n",
    "          - symmetric k-nearest neighbours connectivity matrix of the samples.\n",
    "    n_clusters : int, default=None\n",
    "        Number of clusters to extract.\n",
    "    n_components : int, default=n_clusters\n",
    "        Number of eigen vectors to use for the spectral embedding\n",
    "    eigen_solver : {None, 'arpack', 'lobpcg', or 'amg'}\n",
    "        The eigenvalue decomposition strategy to use. AMG requires pyamg\n",
    "        to be installed. It can be faster on very large, sparse problems,\n",
    "        but may also lead to instabilities. If None, then ``'arpack'`` is\n",
    "        used.\n",
    "    random_state : int, RandomState instance, default=None\n",
    "        A pseudo random number generator used for the initialization of the\n",
    "        lobpcg eigen vectors decomposition when eigen_solver == 'amg' and by\n",
    "        the K-Means initialization. Use an int to make the randomness\n",
    "        deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    n_init : int, default=10\n",
    "        Number of time the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "    eigen_tol : float, default=0.0\n",
    "        Stopping criterion for eigendecomposition of the Laplacian matrix\n",
    "        when using arpack eigen_solver.\n",
    "    assign_labels : {'kmeans', 'discretize'}, default='kmeans'\n",
    "        The strategy to use to assign labels in the embedding\n",
    "        space.  There are two ways to assign labels after the laplacian\n",
    "        embedding.  k-means can be applied and is a popular choice. But it can\n",
    "        also be sensitive to initialization. Discretization is another\n",
    "        approach which is less sensitive to random initialization. See\n",
    "        the 'Multiclass spectral clustering' paper referenced below for\n",
    "        more details on the discretization approach.\n",
    "    verbose : bool, default=False\n",
    "        Verbosity mode.\n",
    "        .. versionadded:: 0.24\n",
    "    Returns\n",
    "    -------\n",
    "    labels : array of integers, shape: n_samples\n",
    "        The labels of the clusters.\n",
    "    References\n",
    "    ----------\n",
    "    - Normalized cuts and image segmentation, 2000\n",
    "      Jianbo Shi, Jitendra Malik\n",
    "      http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324\n",
    "    - A Tutorial on Spectral Clustering, 2007\n",
    "      Ulrike von Luxburg\n",
    "      http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    Notes\n",
    "    -----\n",
    "    The graph should contain only one connect component, elsewhere\n",
    "    the results make little sense.\n",
    "    This algorithm solves the normalized cut for k=2: it is a\n",
    "    normalized spectral clustering.\n",
    "    \"\"\"\n",
    "    if assign_labels not in ('kmeans', 'discretize'):\n",
    "        raise ValueError(\"The 'assign_labels' parameter should be \"\n",
    "                         \"'kmeans' or 'discretize', but '%s' was given\"\n",
    "                         % assign_labels)\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "    n_components = n_clusters if n_components is None else n_components\n",
    "\n",
    "    # The first eigen vector is constant only for fully connected graphs\n",
    "    # and should be kept for spectral clustering (drop_first = False)\n",
    "    # See spectral_embedding documentation.\n",
    "    maps = spectral_embedding(affinity, n_components=n_components,\n",
    "                              eigen_solver=eigen_solver,\n",
    "                              random_state=random_state,\n",
    "                              eigen_tol=eigen_tol, drop_first=False)\n",
    "    if verbose:\n",
    "        print(f'Computing label assignment using {assign_labels}')\n",
    "\n",
    "    if assign_labels == 'kmeans':\n",
    "        _, labels, _ = k_means(maps, n_clusters, random_state=random_state,\n",
    "                               n_init=n_init, verbose=verbose)\n",
    "    else:\n",
    "        labels = discretize(maps, random_state=random_state)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "class SpectralClusteringg(ClusterMixin, BaseEstimator):\n",
    "    \"\"\"Apply clustering to a projection of the normalized Laplacian.\n",
    "    In practice Spectral Clustering is very useful when the structure of\n",
    "    the individual clusters is highly non-convex or more generally when\n",
    "    a measure of the center and spread of the cluster is not a suitable\n",
    "    description of the complete cluster. For instance when clusters are\n",
    "    nested circles on the 2D plane.\n",
    "    If affinity is the adjacency matrix of a graph, this method can be\n",
    "    used to find normalized graph cuts.\n",
    "    When calling ``fit``, an affinity matrix is constructed using either\n",
    "    kernel function such the Gaussian (aka RBF) kernel of the euclidean\n",
    "    distanced ``d(X, X)``::\n",
    "            np.exp(-gamma * d(X,X) ** 2)\n",
    "    or a k-nearest neighbors connectivity matrix.\n",
    "    Alternatively, using ``precomputed``, a user-provided affinity\n",
    "    matrix can be used.\n",
    "    Read more in the :ref:`User Guide <spectral_clustering>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int, default=8\n",
    "        The dimension of the projection subspace.\n",
    "    eigen_solver : {'arpack', 'lobpcg', 'amg'}, default=None\n",
    "        The eigenvalue decomposition strategy to use. AMG requires pyamg\n",
    "        to be installed. It can be faster on very large, sparse problems,\n",
    "        but may also lead to instabilities. If None, then ``'arpack'`` is\n",
    "        used.\n",
    "    n_components : int, default=n_clusters\n",
    "        Number of eigen vectors to use for the spectral embedding\n",
    "    random_state : int, RandomState instance, default=None\n",
    "        A pseudo random number generator used for the initialization of the\n",
    "        lobpcg eigen vectors decomposition when ``eigen_solver='amg'`` and by\n",
    "        the K-Means initialization. Use an int to make the randomness\n",
    "        deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    n_init : int, default=10\n",
    "        Number of time the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "    gamma : float, default=1.0\n",
    "        Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels.\n",
    "        Ignored for ``affinity='nearest_neighbors'``.\n",
    "    affinity : str or callable, default='rbf'\n",
    "        How to construct the affinity matrix.\n",
    "         - 'nearest_neighbors' : construct the affinity matrix by computing a\n",
    "           graph of nearest neighbors.\n",
    "         - 'rbf' : construct the affinity matrix using a radial basis function\n",
    "           (RBF) kernel.\n",
    "         - 'precomputed' : interpret ``X`` as a precomputed affinity matrix.\n",
    "         - 'precomputed_nearest_neighbors' : interpret ``X`` as a sparse graph\n",
    "           of precomputed nearest neighbors, and constructs the affinity matrix\n",
    "           by selecting the ``n_neighbors`` nearest neighbors.\n",
    "         - one of the kernels supported by\n",
    "           :func:`~sklearn.metrics.pairwise_kernels`.\n",
    "        Only kernels that produce similarity scores (non-negative values that\n",
    "        increase with similarity) should be used. This property is not checked\n",
    "        by the clustering algorithm.\n",
    "    n_neighbors : int, default=10\n",
    "        Number of neighbors to use when constructing the affinity matrix using\n",
    "        the nearest neighbors method. Ignored for ``affinity='rbf'``.\n",
    "    eigen_tol : float, default=0.0\n",
    "        Stopping criterion for eigendecomposition of the Laplacian matrix\n",
    "        when ``eigen_solver='arpack'``.\n",
    "    assign_labels : {'kmeans', 'discretize'}, default='kmeans'\n",
    "        The strategy to use to assign labels in the embedding\n",
    "        space. There are two ways to assign labels after the laplacian\n",
    "        embedding. k-means can be applied and is a popular choice. But it can\n",
    "        also be sensitive to initialization. Discretization is another approach\n",
    "        which is less sensitive to random initialization.\n",
    "    degree : float, default=3\n",
    "        Degree of the polynomial kernel. Ignored by other kernels.\n",
    "    coef0 : float, default=1\n",
    "        Zero coefficient for polynomial and sigmoid kernels.\n",
    "        Ignored by other kernels.\n",
    "    kernel_params : dict of str to any, default=None\n",
    "        Parameters (keyword arguments) and values for kernel passed as\n",
    "        callable object. Ignored by other kernels.\n",
    "    n_jobs : int, default=None\n",
    "        The number of parallel jobs to run when `affinity='nearest_neighbors'`\n",
    "        or `affinity='precomputed_nearest_neighbors'`. The neighbors search\n",
    "        will be done in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    verbose : bool, default=False\n",
    "        Verbosity mode.\n",
    "        .. versionadded:: 0.24\n",
    "    Attributes\n",
    "    ----------\n",
    "    affinity_matrix_ : array-like of shape (n_samples, n_samples)\n",
    "        Affinity matrix used for clustering. Available only if after calling\n",
    "        ``fit``.\n",
    "    labels_ : ndarray of shape (n_samples,)\n",
    "        Labels of each point\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.cluster import SpectralClustering\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1, 1], [2, 1], [1, 0],\n",
    "    ...               [4, 7], [3, 5], [3, 6]])\n",
    "    >>> clustering = SpectralClustering(n_clusters=2,\n",
    "    ...         assign_labels=\"discretize\",\n",
    "    ...         random_state=0).fit(X)\n",
    "    >>> clustering.labels_\n",
    "    array([1, 1, 1, 0, 0, 0])\n",
    "    >>> clustering\n",
    "    SpectralClustering(assign_labels='discretize', n_clusters=2,\n",
    "        random_state=0)\n",
    "    Notes\n",
    "    -----\n",
    "    If you have an affinity matrix, such as a distance matrix,\n",
    "    for which 0 means identical elements, and high values means\n",
    "    very dissimilar elements, it can be transformed in a\n",
    "    similarity matrix that is well suited for the algorithm by\n",
    "    applying the Gaussian (RBF, heat) kernel::\n",
    "        np.exp(- dist_matrix ** 2 / (2. * delta ** 2))\n",
    "    Where ``delta`` is a free parameter representing the width of the Gaussian\n",
    "    kernel.\n",
    "    Another alternative is to take a symmetric version of the k\n",
    "    nearest neighbors connectivity matrix of the points.\n",
    "    If the pyamg package is installed, it is used: this greatly\n",
    "    speeds up computation.\n",
    "    References\n",
    "    ----------\n",
    "    - Normalized cuts and image segmentation, 2000\n",
    "      Jianbo Shi, Jitendra Malik\n",
    "      http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324\n",
    "    - A Tutorial on Spectral Clustering, 2007\n",
    "      Ulrike von Luxburg\n",
    "      http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    \"\"\"\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self, n_clusters=8, *, eigen_solver=None, n_components=None,\n",
    "                 random_state=None, n_init=10, gamma=1., affinity='rbf',\n",
    "                 n_neighbors=10, eigen_tol=0.0, assign_labels='kmeans',\n",
    "                 degree=3, coef0=1, kernel_params=None, n_jobs=None,\n",
    "                 verbose=False):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.eigen_solver = eigen_solver\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.n_init = n_init\n",
    "        self.gamma = gamma\n",
    "        self.affinity = affinity\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.eigen_tol = eigen_tol\n",
    "        self.assign_labels = assign_labels\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.kernel_params = kernel_params\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Perform spectral clustering from features, or affinity matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features), or \\\n",
    "                array-like of shape (n_samples, n_samples)\n",
    "            Training instances to cluster, or similarities / affinities between\n",
    "            instances if ``affinity='precomputed'``. If a sparse matrix is\n",
    "            provided in a format other than ``csr_matrix``, ``csc_matrix``,\n",
    "            or ``coo_matrix``, it will be converted into a sparse\n",
    "            ``csr_matrix``.\n",
    "        y : Ignored\n",
    "            Not used, present here for API consistency by convention.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X = self._validate_data(X, accept_sparse=['csr', 'csc', 'coo'],\n",
    "                                dtype=np.float64, ensure_min_samples=2)\n",
    "        allow_squared = self.affinity in [\"precomputed\",\n",
    "                                          \"precomputed_nearest_neighbors\"]\n",
    "        if X.shape[0] == X.shape[1] and not allow_squared:\n",
    "            warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
    "                          \"now constructs an affinity matrix from data. To use\"\n",
    "                          \" a custom affinity matrix, \"\n",
    "                          \"set ``affinity=precomputed``.\")\n",
    "\n",
    "        if self.affinity == 'nearest_neighbors':\n",
    "            connectivity = kneighbors_graph(X, n_neighbors=self.n_neighbors,\n",
    "                                            include_self=True,\n",
    "                                            n_jobs=self.n_jobs)\n",
    "            self.affinity_matrix_ = 0.5 * (connectivity + connectivity.T)\n",
    "        elif self.affinity == 'precomputed_nearest_neighbors':\n",
    "            estimator = NearestNeighbors(n_neighbors=self.n_neighbors,\n",
    "                                         n_jobs=self.n_jobs,\n",
    "                                         metric=\"precomputed\").fit(X)\n",
    "            connectivity = estimator.kneighbors_graph(X=X, mode='connectivity')\n",
    "            self.affinity_matrix_ = 0.5 * (connectivity + connectivity.T)\n",
    "        elif self.affinity == 'precomputed':\n",
    "            self.affinity_matrix_ = X\n",
    "        else:\n",
    "            params = self.kernel_params\n",
    "            if params is None:\n",
    "                params = {}\n",
    "            if not callable(self.affinity):\n",
    "                params['gamma'] = self.gamma\n",
    "                params['degree'] = self.degree\n",
    "                params['coef0'] = self.coef0\n",
    "            self.affinity_matrix_ = pairwise_kernels(X, metric=self.affinity,\n",
    "                                                     filter_params=True,\n",
    "                                                     **params)\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        self.labels_ = spectral_clustering(self.affinity_matrix_,\n",
    "                                           n_clusters=self.n_clusters,\n",
    "                                           n_components=self.n_components,\n",
    "                                           eigen_solver=self.eigen_solver,\n",
    "                                           random_state=random_state,\n",
    "                                           n_init=self.n_init,\n",
    "                                           eigen_tol=self.eigen_tol,\n",
    "                                           assign_labels=self.assign_labels,\n",
    "                                           verbose=self.verbose)\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, X, y=None):\n",
    "        \"\"\"Perform spectral clustering from features, or affinity matrix,\n",
    "        and return cluster labels.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features), or \\\n",
    "                array-like of shape (n_samples, n_samples)\n",
    "            Training instances to cluster, or similarities / affinities between\n",
    "            instances if ``affinity='precomputed'``. If a sparse matrix is\n",
    "            provided in a format other than ``csr_matrix``, ``csc_matrix``,\n",
    "            or ``coo_matrix``, it will be converted into a sparse\n",
    "            ``csr_matrix``.\n",
    "        y : Ignored\n",
    "            Not used, present here for API consistency by convention.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster labels.\n",
    "        \"\"\"\n",
    "        return super().fit_predict(X, y)\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'pairwise': self.affinity in [\"precomputed\",\n",
    "                                              \"precomputed_nearest_neighbors\"]}\n",
    "\n",
    "    # TODO: Remove in 1.1\n",
    "    # mypy error: Decorated property not supported\n",
    "    @deprecated(\"Attribute _pairwise was deprecated in \"  # type: ignore\n",
    "                \"version 0.24 and will be removed in 1.1 (renaming of 0.26).\")\n",
    "    @property\n",
    "    def _pairwise(self):\n",
    "        return self.affinity in [\"precomputed\",\n",
    "                                 \"precomputed_nearest_neighbors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@_deprecate_positional_args\n",
    "def discretize(vectors, *, copy=True, max_svd_restarts=30, n_iter_max=20,\n",
    "               random_state=None):\n",
    "    \"\"\"Search for a partition matrix (clustering) which is closest to the\n",
    "    eigenvector embedding.\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors : array-like of shape (n_samples, n_clusters)\n",
    "        The embedding space of the samples.\n",
    "    copy : bool, default=True\n",
    "        Whether to copy vectors, or perform in-place normalization.\n",
    "    max_svd_restarts : int, default=30\n",
    "        Maximum number of attempts to restart SVD if convergence fails\n",
    "    n_iter_max : int, default=30\n",
    "        Maximum number of iterations to attempt in rotation and partition\n",
    "        matrix search if machine precision convergence is not reached\n",
    "    random_state : int, RandomState instance, default=None\n",
    "        Determines random number generation for rotation matrix initialization.\n",
    "        Use an int to make the randomness deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    Returns\n",
    "    -------\n",
    "    labels : array of integers, shape: n_samples\n",
    "        The labels of the clusters.\n",
    "    References\n",
    "    ----------\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    Notes\n",
    "    -----\n",
    "    The eigenvector embedding is used to iteratively search for the\n",
    "    closest discrete partition.  First, the eigenvector embedding is\n",
    "    normalized to the space of partition matrices. An optimal discrete\n",
    "    partition matrix closest to this normalized embedding multiplied by\n",
    "    an initial rotation is calculated.  Fixing this discrete partition\n",
    "    matrix, an optimal rotation matrix is calculated.  These two\n",
    "    calculations are performed until convergence.  The discrete partition\n",
    "    matrix is returned as the clustering solution.  Used in spectral\n",
    "    clustering, this method tends to be faster and more robust to random\n",
    "    initialization than k-means.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.sparse import csc_matrix\n",
    "    from scipy.linalg import LinAlgError\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    vectors = as_float_array(vectors, copy=copy)\n",
    "\n",
    "    eps = np.finfo(float).eps\n",
    "    n_samples, n_components = vectors.shape\n",
    "\n",
    "    # Normalize the eigenvectors to an equal length of a vector of ones.\n",
    "    # Reorient the eigenvectors to point in the negative direction with respect\n",
    "    # to the first element.  This may have to do with constraining the\n",
    "    # eigenvectors to lie in a specific quadrant to make the discretization\n",
    "    # search easier.\n",
    "    norm_ones = np.sqrt(n_samples)\n",
    "    for i in range(vectors.shape[1]):\n",
    "        vectors[:, i] = (vectors[:, i] / np.linalg.norm(vectors[:, i])) \\\n",
    "            * norm_ones\n",
    "        if vectors[0, i] != 0:\n",
    "            vectors[:, i] = -1 * vectors[:, i] * np.sign(vectors[0, i])\n",
    "\n",
    "    # Normalize the rows of the eigenvectors.  Samples should lie on the unit\n",
    "    # hypersphere centered at the origin.  This transforms the samples in the\n",
    "    # embedding space to the space of partition matrices.\n",
    "    vectors = vectors / np.sqrt((vectors ** 2).sum(axis=1))[:, np.newaxis]\n",
    "\n",
    "    svd_restarts = 0\n",
    "    has_converged = False\n",
    "\n",
    "    # If there is an exception we try to randomize and rerun SVD again\n",
    "    # do this max_svd_restarts times.\n",
    "    while (svd_restarts < max_svd_restarts) and not has_converged:\n",
    "\n",
    "        # Initialize first column of rotation matrix with a row of the\n",
    "        # eigenvectors\n",
    "        rotation = np.zeros((n_components, n_components))\n",
    "        rotation[:, 0] = vectors[random_state.randint(n_samples), :].T\n",
    "\n",
    "        # To initialize the rest of the rotation matrix, find the rows\n",
    "        # of the eigenvectors that are as orthogonal to each other as\n",
    "        # possible\n",
    "        c = np.zeros(n_samples)\n",
    "        for j in range(1, n_components):\n",
    "            # Accumulate c to ensure row is as orthogonal as possible to\n",
    "            # previous picks as well as current one\n",
    "            c += np.abs(np.dot(vectors, rotation[:, j - 1]))\n",
    "            rotation[:, j] = vectors[c.argmin(), :].T\n",
    "\n",
    "        last_objective_value = 0.0\n",
    "        n_iter = 0\n",
    "\n",
    "        while not has_converged:\n",
    "            n_iter += 1\n",
    "\n",
    "            t_discrete = np.dot(vectors, rotation)\n",
    "\n",
    "            labels = t_discrete.argmax(axis=1)\n",
    "            vectors_discrete = csc_matrix(\n",
    "                (np.ones(len(labels)), (np.arange(0, n_samples), labels)),\n",
    "                shape=(n_samples, n_components))\n",
    "\n",
    "            t_svd = vectors_discrete.T * vectors\n",
    "\n",
    "            try:\n",
    "                U, S, Vh = np.linalg.svd(t_svd)\n",
    "                svd_restarts += 1\n",
    "            except LinAlgError:\n",
    "                print(\"SVD did not converge, randomizing and trying again\")\n",
    "                break\n",
    "\n",
    "            ncut_value = 2.0 * (n_samples - S.sum())\n",
    "            if ((abs(ncut_value - last_objective_value) < eps) or \n",
    "                    (n_iter > n_iter_max)):\n",
    "                has_converged = True\n",
    "            else:\n",
    "                # otherwise calculate rotation and continue\n",
    "                last_objective_value = ncut_value\n",
    "                rotation = np.dot(Vh.T, U.T)\n",
    "\n",
    "    if not has_converged:\n",
    "        raise LinAlgError('SVD did not converge')\n",
    "    return labels\n",
    "\n",
    "\n",
    "#@_deprecate_positional_args\n",
    "def spectral_clustering(affinity, *, n_clusters=8, n_components=None,\n",
    "                        eigen_solver=None, random_state=None, n_init=10,\n",
    "                        eigen_tol=0.0, assign_labels='kmeans',\n",
    "                        verbose=False):\n",
    "    \"\"\"Apply clustering to a projection of the normalized Laplacian.\n",
    "    In practice Spectral Clustering is very useful when the structure of\n",
    "    the individual clusters is highly non-convex or more generally when\n",
    "    a measure of the center and spread of the cluster is not a suitable\n",
    "    description of the complete cluster. For instance, when clusters are\n",
    "    nested circles on the 2D plane.\n",
    "    If affinity is the adjacency matrix of a graph, this method can be\n",
    "    used to find normalized graph cuts.\n",
    "    Read more in the :ref:`User Guide <spectral_clustering>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    affinity : {array-like, sparse matrix} of shape (n_samples, n_samples)\n",
    "        The affinity matrix describing the relationship of the samples to\n",
    "        embed. **Must be symmetric**.\n",
    "        Possible examples:\n",
    "          - adjacency matrix of a graph,\n",
    "          - heat kernel of the pairwise distance matrix of the samples,\n",
    "          - symmetric k-nearest neighbours connectivity matrix of the samples.\n",
    "    n_clusters : int, default=None\n",
    "        Number of clusters to extract.\n",
    "    n_components : int, default=n_clusters\n",
    "        Number of eigen vectors to use for the spectral embedding\n",
    "    eigen_solver : {None, 'arpack', 'lobpcg', or 'amg'}\n",
    "        The eigenvalue decomposition strategy to use. AMG requires pyamg\n",
    "        to be installed. It can be faster on very large, sparse problems,\n",
    "        but may also lead to instabilities. If None, then ``'arpack'`` is\n",
    "        used.\n",
    "    random_state : int, RandomState instance, default=None\n",
    "        A pseudo random number generator used for the initialization of the\n",
    "        lobpcg eigen vectors decomposition when eigen_solver == 'amg' and by\n",
    "        the K-Means initialization. Use an int to make the randomness\n",
    "        deterministic.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    n_init : int, default=10\n",
    "        Number of time the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "    eigen_tol : float, default=0.0\n",
    "        Stopping criterion for eigendecomposition of the Laplacian matrix\n",
    "        when using arpack eigen_solver.\n",
    "    assign_labels : {'kmeans', 'discretize'}, default='kmeans'\n",
    "        The strategy to use to assign labels in the embedding\n",
    "        space.  There are two ways to assign labels after the laplacian\n",
    "        embedding.  k-means can be applied and is a popular choice. But it can\n",
    "        also be sensitive to initialization. Discretization is another\n",
    "        approach which is less sensitive to random initialization. See\n",
    "        the 'Multiclass spectral clustering' paper referenced below for\n",
    "        more details on the discretization approach.\n",
    "    verbose : bool, default=False\n",
    "        Verbosity mode.\n",
    "        .. versionadded:: 0.24\n",
    "    Returns\n",
    "    -------\n",
    "    labels : array of integers, shape: n_samples\n",
    "        The labels of the clusters.\n",
    "    References\n",
    "    ----------\n",
    "    - Normalized cuts and image segmentation, 2000\n",
    "      Jianbo Shi, Jitendra Malik\n",
    "      http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324\n",
    "    - A Tutorial on Spectral Clustering, 2007\n",
    "      Ulrike von Luxburg\n",
    "      http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323\n",
    "    - Multiclass spectral clustering, 2003\n",
    "      Stella X. Yu, Jianbo Shi\n",
    "      https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf\n",
    "    Notes\n",
    "    -----\n",
    "    The graph should contain only one connect component, elsewhere\n",
    "    the results make little sense.\n",
    "    This algorithm solves the normalized cut for k=2: it is a\n",
    "    normalized spectral clustering.\n",
    "    \"\"\"\n",
    "    if assign_labels not in ('kmeans', 'discretize'):\n",
    "        raise ValueError(\"The 'assign_labels' parameter should be \"\n",
    "                         \"'kmeans' or 'discretize', but '%s' was given\"\n",
    "                         % assign_labels)\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "    n_components = n_clusters if n_components is None else n_components\n",
    "\n",
    "    # The first eigen vector is constant only for fully connected graphs\n",
    "    # and should be kept for spectral clustering (drop_first = False)\n",
    "    # See spectral_embedding documentation.\n",
    "    maps = spectral_embedding(affinity, n_components=n_components,\n",
    "                              eigen_solver=eigen_solver,\n",
    "                              random_state=random_state,\n",
    "                              eigen_tol=eigen_tol, drop_first=False)\n",
    "    if verbose:\n",
    "        print(f'Computing label assignment using {assign_labels}')\n",
    "\n",
    "    if assign_labels == 'kmeans':\n",
    "        _, labels, _ = k_means(maps, n_clusters, random_state=random_state,\n",
    "                               n_init=n_init, verbose=verbose)\n",
    "    else:\n",
    "        labels = discretize(maps, random_state=random_state)\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
